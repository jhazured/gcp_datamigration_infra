# Spark Configuration for GCP ETL Operations

# === Core Spark Settings ===
spark.app.name                    ETL-Framework
spark.master                      local[*]
spark.sql.adaptive.enabled        true
spark.sql.adaptive.coalescePartitions.enabled  true
spark.sql.adaptive.skewJoin.enabled            true
spark.serializer                   org.apache.spark.serializer.KryoSerializer

# === Google Cloud Storage Configuration ===
spark.hadoop.fs.gs.impl                    com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
spark.hadoop.fs.AbstractFileSystem.gs.impl com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.fs.gs.auth.service.account.enable true
spark.hadoop.fs.gs.project.id              your-gcp-project-id
spark.hadoop.google.cloud.auth.service.account.json.keyfile /app/service-account-key.json

# === BigQuery Configuration ===
spark.sql.catalog.spark_catalog             com.google.cloud.spark.bigquery.v2.BigQueryTableProvider
spark.conf.set                              spark.sql.catalog.spark_catalog.gcpAccessToken

# === Memory and Performance Optimization ===
spark.executor.memory                       2g
spark.executor.cores                        2
spark.executor.instances                    2
spark.driver.memory                         1g
spark.driver.maxResultSize                  1g
spark.sql.execution.arrow.pyspark.enabled   true
spark.sql.execution.arrow.maxRecordsPerBatch 10000

# === Checkpointing and Recovery ===
spark.sql.streaming.checkpointLocation      /app/checkpoints
spark.sql.recovery.checkpointOnExit         true

# === Logging and Monitoring ===
spark.eventLog.enabled                      true
spark.eventLog.dir                          /app/spark-events
spark.history.fs.logDirectory               /app/spark-events
spark.ui.enabled                            true
spark.ui.port                               4040

# === ETL Specific Settings ===
spark.sql.sources.partitionOverwriteMode    dynamic
spark.sql.parquet.compression.codec         snappy
spark.sql.parquet.mergeSchema               true
spark.sql.parquet.filterPushdown            true
spark.sql.adaptive.advisoryPartitionSizeInBytes 128MB

# === Network and Timeouts ===
spark.network.timeout                       800s
spark.sql.broadcastTimeout                  36000
spark.rpc.askTimeout                        600s
spark.rpc.lookupTimeout                     600s

# === Temporary Storage ===
spark.local.dir                             /app/temp
spark.sql.warehouse.dir                     /app/spark-warehouse